version: '3'
services:
  scrapy:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app
    depends_on:
      - postgres_db
      - mongodb
      - redis
    environment:
      - POSTGRES_HOST=host.docker.internal
      - POSTGRES_PORT=5432
      - POSTGRES_DB=jobs_database
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=passWORD
      - POSTGRES_TABLE_NAME=raw_table
      - MONGO_HOST=host.docker.internal
      - MONGO_PORT=27017
      - MONGO_DB=mongodb_canaria
      - MONGO_COLLECTION_NAME=raw_collection
      - MONGO_USERNAME=ismail
      - MONGO_PASSWORD=passWORD
    working_dir: /app/jobs_project
    command: sh -c "scrapy crawl job_spider && python ../query.py"

  postgres_db:
    image: postgres:latest
    environment:
      POSTGRES_DB: 'jobs_database'
      POSTGRES_USER: 'postgres'
      POSTGRES_PASSWORD: 'passWORD'
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mongodb:
    image: mongo:4.4.6
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: ["sh", "-c", "rm -rf /data/* && redis-server"]  

volumes:
  postgres_data:
  mongo_data:
  redis_data:
